{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_learning_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "szdgJmSEi5ZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab        import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import getpass\n",
        "\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "auth.authenticate_user()\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "\n",
        "vcode = getpass.getpass()\n",
        "\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4J5gjlEjbqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOWdsRSabO2-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36729864-eb95-4881-cf73-1e0a5ad5b4c9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing   import LabelBinarizer\n",
        "from tensorflow              import keras\n",
        "from keras.callbacks         import ModelCheckpoint\n",
        "from keras.models            import Sequential\n",
        "from keras.layers            import Dense, Flatten, Conv2D, Dropout\n",
        "from os.path                 import join\n",
        "from keras.optimizers        import Adam\n",
        "\n",
        "import keras.backend     as K\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow        as tf\n",
        "import numpy             as np\n",
        "import pandas            as pd\n",
        "import seaborn           as sb\n",
        "import pdb, os, random, keras\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9smtlNWiBxWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm /content/Weights*.hdf5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnZX3DhVD6Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 list | grep tensorflow\n",
        "!pip3 install tensorflow==1.13.1 # the binary is still in the 1.13.1 version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lihceFjcKGm",
        "colab_type": "text"
      },
      "source": [
        "## Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiUueStR0xdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xNormalize(value, max_value, min_value):\n",
        "    return (value - min_value)/(max_value - min_value)\n",
        "\n",
        "def yNormalize(value, max_value):\n",
        "    if value < 0:\n",
        "        return -1\n",
        "    \n",
        "    return value\n",
        "\n",
        "def load_data2(directory):\n",
        "    all_files = [join(directory, filename) for filename in os.listdir(directory)]\n",
        "    \n",
        "    random.shuffle(all_files)\n",
        "    \n",
        "    first_file = all_files.pop(0) \n",
        "    all_data   = pd.read_csv(first_file)\n",
        "    \n",
        "    for file in all_files:\n",
        "        data = pd.read_csv(file)\n",
        "        \n",
        "        all_data = all_data.append(data)\n",
        "        \n",
        "    return all_data\n",
        "\n",
        "def load_data(filepath):\n",
        "    data = pd.read_csv(filepath)\n",
        "    data = data.sample(frac=1)\n",
        "    \n",
        "    return data\n",
        "\n",
        "def get_coordID_values(num_nodes):\n",
        "    values = []\n",
        "    \n",
        "    for i in range(1, number_of_nodes + 1):\n",
        "        values.append('CoordID_' + str(i))\n",
        "        \n",
        "    return values\n",
        "    \n",
        "def get_estimatePeerID_values(num_nodes):\n",
        "    values = []\n",
        "    \n",
        "    for i in range(1, number_of_nodes + 1):\n",
        "        values.append('EstimatePeerID_' + str(i))\n",
        "        \n",
        "    return values\n",
        "\n",
        "def print_layer(layer, message, first_n=3, summarize=1024):\n",
        "    return keras.layers.Lambda((\n",
        "        lambda x: tf.Print(x, [x],\n",
        "                           message=message,\n",
        "                           first_n=first_n,\n",
        "                           summarize=summarize)))(layer)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EunUbwmQcJGP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9d1f0ba-bce5-43c2-8521-09105bc5081c"
      },
      "source": [
        "number_of_nodes          = 40\n",
        "algorithm_variables      = 8\n",
        "matrix_rows, matrix_cols = 1, (algorithm_variables - 4) + number_of_nodes*4 + 2 \n",
        "\n",
        "filepath = 'sample_data/snapshots_' + str(number_of_nodes)  + '.csv'\n",
        "data     = load_data(filepath)\n",
        "\n",
        "train_set_size = int(len(data) * 0.8)\n",
        "\n",
        "data_np = data.to_numpy()\n",
        "delay   = data_np[:, (algorithm_variables + number_of_nodes):]\n",
        "\n",
        "max_val_delay = np.amax(delay)\n",
        "min_val_delay = np.amin(delay)\n",
        "\n",
        "data_norm = pd.get_dummies(data, \n",
        "                           columns=['EstimateValue', 'Decision', 'PeerID', 'Phase', 'EstimatePeerID', 'CoordID'],\n",
        "                           prefix=['EstimateValue', 'Decision', 'PeerID', 'Phase', 'EstimatePeerID', 'CoordID'])\n",
        "\n",
        "current_estimatePeerID_values = list(filter(lambda x: 'EstimatePeerID' in x, data_norm.columns.values))\n",
        "current_coordID_values        = list(filter(lambda x: 'CoordID'        in x, data_norm.columns.values))\n",
        "current_phase_value           = list(filter(lambda x: 'Phase'          in x, data_norm.columns.values))\n",
        "\n",
        "coordID_values        = get_coordID_values(number_of_nodes)\n",
        "EstimatePeerID_values = get_estimatePeerID_values(number_of_nodes)\n",
        "phase_values          = ['Phase_1', 'Phase_2']\n",
        "\n",
        "phase_colums          = data_norm.T.reindex(phase_values).T.fillna(0)\n",
        "coordID_columns       = data_norm.T.reindex(coordID_values).T.fillna(0)\n",
        "estimatePeerID_colums = data_norm.T.reindex(EstimatePeerID_values).T.fillna(0)\n",
        "\n",
        "data_norm.drop(current_estimatePeerID_values + current_coordID_values + current_phase_value, \n",
        "               inplace=True, \n",
        "               axis=1) \n",
        "\n",
        "data_norm = pd.concat([data_norm, coordID_columns, estimatePeerID_colums, phase_colums], axis=1)\n",
        "data_np   = data_norm.to_numpy()\n",
        "\n",
        "delays        = []\n",
        "mut_variables = []\n",
        "\n",
        "for row in data_np:\n",
        "    splited_data    = np.split(row, [2 + number_of_nodes, 2 + (number_of_nodes*2)])\n",
        "    aggregated_data = np.concatenate((splited_data[0], splited_data[2]), axis=None)\n",
        "    \n",
        "    mut_variables.append([aggregated_data])\n",
        "    delays.append([splited_data[1]])\n",
        "\n",
        "delays = [[[ yNormalize(element, max_val_delay) for element in list] for list in matrix] for matrix in delays]\n",
        "\n",
        "delays        = np.asarray(delays)\n",
        "mut_variables = np.asarray(mut_variables)\n",
        "\n",
        "mut_variables_train = mut_variables[:train_set_size]\n",
        "mut_variables_test  = mut_variables[train_set_size:]\n",
        "\n",
        "delays_train = delays[:train_set_size]\n",
        "delays_test  = delays[train_set_size:]\n",
        "\n",
        "print('Done')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KRBa_Ku95aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C_mat = data.corr()\n",
        "fig   = plt.figure(figsize=(50,50))\n",
        "\n",
        "sb.heatmap(C_mat, vmax = 1., square = True)\n",
        "#plt.show()\n",
        "plt.savefig('foo2.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY3x37EccXAT",
        "colab_type": "text"
      },
      "source": [
        "## Train, compile and fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiFOtpKlbzya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "sess       = tf.Session()  \n",
        "\n",
        "K.set_session(sess)\n",
        "\n",
        "# Activation function\n",
        "activation = 'relu'\n",
        "\n",
        "# Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# First layer\n",
        "# The Input Layer :\n",
        "model.add(Dense(256, \n",
        "                kernel_initializer='normal', \n",
        "                input_shape=(1, matrix_cols), \n",
        "                activation=activation, \n",
        "                name=\"input_layer\"))\n",
        "\n",
        "# The Hidden Layers :\n",
        "model.add(Dense(128, kernel_initializer='normal',activation=activation))\n",
        "model.add(Dense(128, kernel_initializer='normal',activation=activation))\n",
        "model.add(Dense(128, kernel_initializer='normal',activation=activation))\n",
        "\n",
        "# The Output Layer :\n",
        "model.add(Dense(number_of_nodes, \n",
        "                kernel_initializer='normal', \n",
        "                activation='linear', \n",
        "                name=\"output_layer\"))\n",
        "\n",
        "# Compile the network :\n",
        "\n",
        "# adam = Adam(lr=0.0001)\n",
        "adam = 'adam'\n",
        "model.compile(loss='mean_absolute_error', \n",
        "              optimizer=adam, \n",
        "              metrics=['mean_absolute_error'])\n",
        "model.summary()\n",
        "\n",
        "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "checkpoint      = ModelCheckpoint(checkpoint_name, \n",
        "                                  monitor='val_loss', \n",
        "                                  verbose=1, \n",
        "                                  save_best_only = True, \n",
        "                                  mode ='auto')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Fit \n",
        "model.fit(mut_variables_train, \n",
        "          delays_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=100,\n",
        "          validation_split=0.2,\n",
        "          callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mok4FJMxDLQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghHPqO3dgjH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data_norm.columns.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD-BpQFpyV5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_eibqJ1oyNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "wights_file = 'Weights-070--0.02363.hdf5' # choose the best checkpoint \n",
        "adam        = 'adam'\n",
        "#adam        = Adam(lr=0.0001)\n",
        "\n",
        "model.load_weights(wights_file)  \n",
        "model.compile(loss='mean_absolute_error', \n",
        "              optimizer=adam, \n",
        "              metrics=['mean_absolute_error'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXfnyK3ltoIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get input and output layer name\n",
        "for n in sess.graph.as_graph_def().node:\n",
        "    if 'input_layer' in n.name:\n",
        "          print(n.name)\n",
        "    if 'output_layer' in n.name:\n",
        "          print(n.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzg_WmHwROjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(mut_variables_test)\n",
        "\n",
        "for i in range(30):\n",
        "    print(mut_variables_test[i][0][(4 + (number_of_nodes)):(4 + (number_of_nodes*2))])\n",
        "    print(delays_test[i][0])\n",
        "    print(predictions[i][0][:10])\n",
        "    print(\"----------\" + str(i))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBLSj_kCV3ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use TF to save the graph model instead of Keras save model to load it in Golang\n",
        "builder = tf.saved_model.builder.SavedModelBuilder(\"/content/drive/datasets/mut_model_40.5\")  \n",
        "# Tag the model, required for Go\n",
        "builder.add_meta_graph_and_variables(sess, [\"mut_tag\"], clear_devices=True)  \n",
        "builder.save()\n",
        "# sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}